{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0Vf_a5BbcES",
        "outputId": "3572ee2a-da0d-454a-c148-ee89a92540f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gotm34vMeb8w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.losses import categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrVg68tyecC_",
        "outputId": "cf013c6e-981d-485c-9539-2d4419292c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6994 images belonging to 7 classes.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'angry': 0,\n",
              " 'disgust': 1,\n",
              " 'fear': 2,\n",
              " 'happy': 3,\n",
              " 'neutral': 4,\n",
              " 'sad': 5,\n",
              " 'surprise': 6}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "     zoom_range = 0.2,\n",
        "     shear_range = 0.2,\n",
        "     horizontal_flip=True,\n",
        "     rescale = 1./255\n",
        ")\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(directory= \"/content/drive/MyDrive/7 types of images\",\n",
        "                                               target_size=(224,224),\n",
        "                                               batch_size=32,\n",
        "                                  )\n",
        "\n",
        "\n",
        "train_data.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YXcFLVdecEr",
        "outputId": "9cf856ec-4d1d-40f2-d28f-f88108424838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6994 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "val_datagen = ImageDataGenerator(rescale = 1./255 )\n",
        "\n",
        "val_data = val_datagen.flow_from_directory(directory= \"/content/drive/MyDrive/7 types of images\",\n",
        "                                           target_size=(224,224),\n",
        "                                           batch_size=32,\n",
        "                                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS1o3_qDecI6",
        "outputId": "60e05466-3011-40f7-f2ec-b35d7c314abd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#  Build CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation=\"relu\", input_shape=(224,224,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation=\"relu\"),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_data.num_classes, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPa3Zsf-fGVn"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# early stopping\n",
        "es = EarlyStopping(\n",
        "    monitor='val_accuracy',  # watch validation accuracy\n",
        "    min_delta=0.01,          # must improve by at least 1%\n",
        "    patience=5,              # wait 5 epochs before stopping\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "# put callback in a list\n",
        "call_back = [es]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOqKQIEBecKm"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WzlztxWfSxu",
        "outputId": "91de8d32-122e-4142-ec3b-9976563365ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2055s\u001b[0m 9s/step - accuracy: 0.1859 - loss: 2.4561 - val_accuracy: 0.3017 - val_loss: 1.7860\n",
            "Epoch 2/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 565ms/step - accuracy: 0.2803 - loss: 1.8284 - val_accuracy: 0.3329 - val_loss: 1.7247\n",
            "Epoch 3/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 566ms/step - accuracy: 0.3090 - loss: 1.7745 - val_accuracy: 0.3679 - val_loss: 1.6542\n",
            "Epoch 4/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 556ms/step - accuracy: 0.3354 - loss: 1.7156 - val_accuracy: 0.3971 - val_loss: 1.5914\n",
            "Epoch 5/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 563ms/step - accuracy: 0.3548 - loss: 1.6846 - val_accuracy: 0.4269 - val_loss: 1.5269\n",
            "Epoch 6/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 649ms/step - accuracy: 0.3671 - loss: 1.6385 - val_accuracy: 0.4319 - val_loss: 1.4960\n",
            "Epoch 7/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 645ms/step - accuracy: 0.3773 - loss: 1.6000 - val_accuracy: 0.4625 - val_loss: 1.4207\n",
            "Epoch 8/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 557ms/step - accuracy: 0.4071 - loss: 1.5679 - val_accuracy: 0.4901 - val_loss: 1.4040\n",
            "Epoch 9/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 562ms/step - accuracy: 0.4274 - loss: 1.5135 - val_accuracy: 0.4991 - val_loss: 1.3395\n",
            "Epoch 10/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 645ms/step - accuracy: 0.4411 - loss: 1.4786 - val_accuracy: 0.5250 - val_loss: 1.2942\n",
            "Epoch 11/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 645ms/step - accuracy: 0.4431 - loss: 1.4486 - val_accuracy: 0.5285 - val_loss: 1.2751\n",
            "Epoch 12/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 554ms/step - accuracy: 0.4620 - loss: 1.4236 - val_accuracy: 0.5470 - val_loss: 1.2571\n",
            "Epoch 13/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 646ms/step - accuracy: 0.4639 - loss: 1.4138 - val_accuracy: 0.5722 - val_loss: 1.1959\n",
            "Epoch 14/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 559ms/step - accuracy: 0.4729 - loss: 1.3995 - val_accuracy: 0.5698 - val_loss: 1.1625\n",
            "Epoch 15/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 557ms/step - accuracy: 0.5047 - loss: 1.3403 - val_accuracy: 0.5894 - val_loss: 1.1610\n",
            "Epoch 16/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 562ms/step - accuracy: 0.4902 - loss: 1.3404 - val_accuracy: 0.5875 - val_loss: 1.1839\n",
            "Epoch 17/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 558ms/step - accuracy: 0.5023 - loss: 1.3303 - val_accuracy: 0.6044 - val_loss: 1.0637\n",
            "Epoch 18/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 576ms/step - accuracy: 0.5069 - loss: 1.2952 - val_accuracy: 0.6094 - val_loss: 1.0610\n",
            "Epoch 19/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 577ms/step - accuracy: 0.5252 - loss: 1.2713 - val_accuracy: 0.6120 - val_loss: 1.0886\n",
            "Epoch 20/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 566ms/step - accuracy: 0.5161 - loss: 1.2766 - val_accuracy: 0.6385 - val_loss: 1.0244\n",
            "Epoch 21/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 572ms/step - accuracy: 0.5356 - loss: 1.2323 - val_accuracy: 0.6397 - val_loss: 0.9894\n",
            "Epoch 22/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 570ms/step - accuracy: 0.5287 - loss: 1.2309 - val_accuracy: 0.6516 - val_loss: 0.9594\n",
            "Epoch 23/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 566ms/step - accuracy: 0.5287 - loss: 1.2214 - val_accuracy: 0.6488 - val_loss: 0.9733\n",
            "Epoch 24/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 575ms/step - accuracy: 0.5357 - loss: 1.2037 - val_accuracy: 0.6730 - val_loss: 0.9225\n",
            "Epoch 25/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 661ms/step - accuracy: 0.5451 - loss: 1.1921 - val_accuracy: 0.6719 - val_loss: 0.9415\n",
            "Epoch 26/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 572ms/step - accuracy: 0.5441 - loss: 1.1976 - val_accuracy: 0.6786 - val_loss: 0.9214\n",
            "Epoch 27/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 574ms/step - accuracy: 0.5516 - loss: 1.1687 - val_accuracy: 0.6899 - val_loss: 0.8789\n",
            "Epoch 28/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 649ms/step - accuracy: 0.5670 - loss: 1.1306 - val_accuracy: 0.6916 - val_loss: 0.8384\n",
            "Epoch 29/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 572ms/step - accuracy: 0.5641 - loss: 1.1630 - val_accuracy: 0.7112 - val_loss: 0.8447\n",
            "Epoch 30/30\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 652ms/step - accuracy: 0.5803 - loss: 1.1330 - val_accuracy: 0.7017 - val_loss: 0.8553\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(\n",
        "    train_data,\n",
        "    epochs=30,\n",
        "    validation_data=val_data,\n",
        "    callbacks=[es]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVpDOiTtfS6w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMJtQJAHNz/caIB2uhjDIbi"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}